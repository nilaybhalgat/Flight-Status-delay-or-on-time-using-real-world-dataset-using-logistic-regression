{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "df=pd.read_csv('FlightDelays.csv')\n",
    "m=len(df)\n",
    "#making time continuous \n",
    "q=df['DEP_TIME']\n",
    "p=df['CRS_DEP_TIME']\n",
    "a=p\n",
    "for i in range(m):\n",
    "    a[i]=int(p[i]/100)*60+p[i]-int(p[i]/100)*100\n",
    "b=q\n",
    "for i in range(m):\n",
    "    b[i]=int(q[i]/100)*60+q[i]-int(q[i]/100)*100\n",
    "df['DEP_TIME']=b\n",
    "df['CRS_DEP_TIME']=a\n",
    "\n",
    "\n",
    "\n",
    "df.loc[(df.DEP_TIME <= 100),'DEP_TIME']+=1440\n",
    "\n",
    "#indexNames = df[ df['DEP_TIME'] <= 100 ].index\n",
    "# Delete these row indexes from dataFrame\n",
    "#df.drop(indexNames , inplace=True)\n",
    "print(df.head())\n",
    "df=df.sample(frac=1,random_state=42);\n",
    "print(df.describe())\n",
    "print(df['FL_NUM'].nunique())\n",
    "print(df['TAIL_NUM'].nunique())\n",
    "#from info method we can observe that there are no null values in the given dataset\n",
    "#from heatmap of correlation matrix we can infer there is good corelation between CRS_DEP_TIME and DEP_TIME\n",
    "#from describe method we can infer that the delays caused by weather conditions are less,number of samples are 2201\\\n",
    "\n",
    "olddf=df\n",
    "\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Weather'])['Flight Status'].value_counts(normalize=True)\n",
    "df.groupby(['ORIGIN'])['Flight Status'].value_counts(normalize=True)\n",
    "df.groupby(['CARRIER'])['Flight Status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.heatmap(df.corr())\n",
    "\n",
    "y=df.loc[:,'Flight Status']\n",
    "df['year'] = pd.DatetimeIndex(df['FL_DATE']).year\n",
    "df['month'] = pd.DatetimeIndex(df['FL_DATE']).month\n",
    "df=df.drop(columns=['FL_DATE','Flight Status'])\n",
    "for column in df.columns:\n",
    "    if df[column].dtype==object:\n",
    "        dummyCols=pd.get_dummies(df[column])\n",
    "        df=df.join(dummyCols)\n",
    "        del df[column]\n",
    "print(df.head())        \n",
    "y=y.replace(['ontime','delayed'],[0,1])\n",
    "print(y)\n",
    "\n",
    "y.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "z = df['DEP_TIME']-df['CRS_DEP_TIME']\n",
    "x=df['CRS_DEP_TIME']\n",
    "label = y\n",
    "colors = ['green','red']\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.scatter(x, z, c=label, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "plt.xlabel('crs_dep_time')\n",
    "plt.ylabel('difference in time')\n",
    "\n",
    "\n",
    "z = df['Weather']\n",
    "x=df['DEP_TIME']\n",
    "label = y\n",
    "colors = ['green','red']\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.scatter(x, z, c=label, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "plt.xlabel('dep_time')\n",
    "plt.ylabel('weather')\n",
    "\n",
    "\n",
    "z = df['DISTANCE']\n",
    "x=df['DEP_TIME']\n",
    "label = y\n",
    "colors = ['green','red']\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.scatter(x, z, c=label, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "plt.xlabel('dep_time')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "#from the scatter plot of dep_time-crs_dep_time vs crs_dep_time one can clearly see that the flight delayed \n",
    "#when difference is more .So the difference is one of the features. also seems like there are 2 outliers which are to be taken care of.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg=LogisticRegression(C=0.01,max_iter=500)\n",
    "\n",
    "X=df;\n",
    "X_train,X_test,y_train,y_test=train_test_split(df,y,test_size=0.4,random_state=42)\n",
    "log_reg.fit(X_train,y_train)\n",
    "y_pred=log_reg.predict(X_test);\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(log_reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the coefficients it is very clear that crs_dep_time , dep_time , weather are the most important features \n",
    "#the dummy features created from flight numbers and tail numbers are least important \n",
    "#due to these large number of unnecessary dummy variables it seems that the accuracy achieved is lower \n",
    "#Logistic Regression is the right model for this problem, as the problem is a binary classification problem.\n",
    "#SVM, KNN ,Decision tree algorithms can also be used but as training data is less, there are only two outliers, after removal of \n",
    "#irrelevant features there are only 3 categorical features, significantly more number of features \n",
    "#implies that Logistic Regression is best choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As stated earlier flight number, month , year , tail number are not the relavant feature removing them from feature set\n",
    "df=olddf;\n",
    "df=df.drop(columns=['FL_DATE','Flight Status','FL_NUM','TAIL_NUM'])\n",
    "for column in df.columns:\n",
    "    if df[column].dtype==object:\n",
    "        dummyCols=pd.get_dummies(df[column])\n",
    "        df=df.join(dummyCols)\n",
    "        del df[column]\n",
    "print(df.head())  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg=LogisticRegression(C=0.01,max_iter=500)\n",
    "scaler=StandardScaler()\n",
    "X=df;\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "log_reg.fit(X_train,y_train)\n",
    "y_pred=log_reg.predict(X_test);\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(y_test.value_counts())\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(log_reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
